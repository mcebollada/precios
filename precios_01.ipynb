{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcebollada/precios/blob/main/precios_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Uvi2z68A9vT"
      },
      "outputs": [],
      "source": [
        "# prompt: generare an function what create connect to mariadb gatabase and return handler. generare an function what  create connect with url to site and return read page\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install mysql-connector-python requests\n",
        "\n",
        "import mysql.connector\n",
        "import requests\n",
        "\n",
        "def connect_to_mariadb(db_config):\n",
        "  \"\"\"\n",
        "  Connects to a MariaDB database and returns a connection handler.\n",
        "\n",
        "  Args:\n",
        "    db_config: A dictionary containing database connection details.\n",
        "\n",
        "    db_config = {\n",
        "        'host': 'your_host',\n",
        "        'user': 'your_user',\n",
        "        'password': 'your_password',\n",
        "        'database': 'your_database'\n",
        "    }\n",
        "\n",
        "  Returns:\n",
        "    A mysql.connector.MySQLConnection object.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Connect to the database\n",
        "    mydb = mysql.connector.connect(**db_config)\n",
        "    print(\"Connected to MariaDB database!\")\n",
        "    return mydb\n",
        "  except mysql.connector.Error as err:\n",
        "    print(f\"Error connecting to MariaDB: {err}\")\n",
        "    return None\n",
        "\n",
        "def get_website_content(url):\n",
        "  \"\"\"\n",
        "  Connects to a website and returns the content of the page.\n",
        "\n",
        "  Args:\n",
        "    url: The URL of the website.\n",
        "\n",
        "  Returns:\n",
        "    The content of the page as a string, or None if an error occurs.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # Send a GET request to the website\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "    return response.text\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error accessing the website: {e}\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTjN3qigDVT8"
      },
      "outputs": [],
      "source": [
        "#url=\"https://www.carrefour.com.ar/almacen?order=OrderByNameDESC&page=2\"\n",
        "url=\"https://www.disco.com.ar/bebidas\"\n",
        "cadena0 =get_website_content(url)\n",
        "cadena=cadena0\n",
        "\n",
        "print(len(cadena))\n",
        "#print(cadena)\n",
        "subcad0 = '<script type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"itemlist\",\"itemlistelement\":'\n",
        "subcad = '<script type=\"'\n",
        "#subcad = '\"sku\":'\n",
        "cantidad = cadena.count(subcad)\n",
        "posi = [cadena.find(subcad)]\n",
        "cuen=0\n",
        "lo=cadena.find(subcad)\n",
        "while(len(posi)<cantidad):\n",
        "  posi.append(cadena.find(subcad,int(posi[-1])+6))\n",
        "print(cantidad, posi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXIIHDhnImWQ"
      },
      "outputs": [],
      "source": [
        "# prompt: build robot to navigate a site and tracking links\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def crawl_website(start_url, max_depth=2):\n",
        "  \"\"\"\n",
        "  Crawls a website and tracks links.\n",
        "\n",
        "  Args:\n",
        "    start_url: The starting URL for the crawl.\n",
        "    max_depth: The maximum depth to crawl.\n",
        "  \"\"\"\n",
        "  visited_urls = set()\n",
        "\n",
        "  def crawl_recursive(url, depth):\n",
        "    if depth > max_depth or url in visited_urls:\n",
        "      return\n",
        "\n",
        "    visited_urls.add(url)\n",
        "    print(f\"Visiting: {url}\")\n",
        "\n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      cadena = response.text.lower()\n",
        "      subcad0 = '<script type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"itemlist\",\"itemlistelement\":'\n",
        "      subcad = '<script type=\"application/ld+json\">'\n",
        "      cantidad = cadena.count(subcad)\n",
        "      posi = [cadena.find(subcad)]\n",
        "      cuen=0\n",
        "      lo=cadena.find(subcad)\n",
        "      while(len(posi)<cantidad):\n",
        "        posi.append(cadena.find(subcad,int(posi[-1])+6))\n",
        "      print(cantidad, posi)\n",
        "      #lista =\n",
        "      print(cadena[posi[0]+len(subcad):cadena.find('</script>',posi[0])])\n",
        "      #for i in lista:\n",
        "      #  print(i)\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "\n",
        "      #print(response.text)\n",
        "\n",
        "      # Find all links on the page\n",
        "      links = soup.find_all('a', href=True)\n",
        "      for link in links:\n",
        "        absolute_url = urljoin(url, link['href'])\n",
        "        crawl_recursive(absolute_url, depth + 1)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error accessing the website: {e}\")\n",
        "\n",
        "  crawl_recursive(start_url, 0)\n",
        "\n",
        "# Example usage:\n",
        "start_url = \"https://www.disco.com.ar/bebidas\"\n",
        "crawl_website(start_url)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNY9OCHvXwL56mHGXJ03Ibd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}